{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarukiKozukapenguin/FixedHydrus_imitation_navigation/blob/main/Project%E8%AA%B2%E9%A1%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFpUUOLdCJdY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import csv\n",
        "import random\n",
        "from scipy.spatial import KDTree\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "import glob\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPoblgyJ-1MG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import random\n",
        "from scipy.spatial import KDTree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Node:\n",
        "    \"\"\"\n",
        "    Node class for dijkstra search\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x, y, yaw, cost, parent_index):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.yaw = yaw\n",
        "        self.cost = cost\n",
        "        self.parent_index = parent_index\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.x) + \",\" + str(self.y) + \",\"+ str(self.yaw) + \",\" +\\\n",
        "               str(self.cost) + \",\" + str(self.parent_index)\n",
        "\n",
        "# 自作エラー,pathが見つからなかった場合に使用\n",
        "class InitCollisionError(Exception):\n",
        "    pass\n",
        "class GoalCollisionError(Exception):\n",
        "    pass\n",
        "class PathNotFoundError(Exception):\n",
        "    pass\n",
        "\n",
        "class Prm:\n",
        "    def __init__(self, robot_theta: list, edge_l: float, fly_area: list, tree_csv: str, file_num: int, x_add_range:float, y_add_range:float, act_norm: float):\n",
        "        self.N_KNN = 10  # number of edge from one sampled point\n",
        "        self.MAX_EDGE_LEN = 5.0  # [m] Maximum edge length\n",
        "        self.yaw_weight = 2.0\n",
        "        self.show_animation = True\n",
        "        self.edge_l = edge_l\n",
        "        self.act_norm = act_norm\n",
        "        self.change_edge = True\n",
        "\n",
        "        theta: list = [np.deg2rad(i) for i in robot_theta] # from deg to rad\n",
        "        bR2: np.array = np.array([0.0,0.0])\n",
        "        bC2 = np.array([-edge_l/2,0.0])\n",
        "        bC2ToR1 = np.array([-edge_l/2*np.cos(theta[0]),edge_l/2*np.sin(theta[0])])\n",
        "        bR1 = bC2+bC2ToR1\n",
        "        bC1 = bC2+bC2ToR1*2\n",
        "        bC3 = np.array([edge_l/2,0.0])\n",
        "        bC3ToR3 = np.array([edge_l/2*np.cos(theta[1]),edge_l/2*np.sin(theta[1])])\n",
        "        bR3 = bC3+bC3ToR3\n",
        "        bC4 = bC3+bC3ToR3*2\n",
        "        bC4ToR4 = np.array([edge_l/2*np.cos(theta[1]+theta[2]),edge_l/2*np.sin(theta[1]+theta[2])])\n",
        "        bR4 = bC4+bC4ToR4\n",
        "        bC5 = bC4+bC4ToR4*2\n",
        "        CG = (bR1+bR2+bR3+bR4)/4\n",
        "        C_list = [bC1-CG,bC2-CG,bC3-CG,bC4-CG,bC5-CG]\n",
        "        mid_point = []\n",
        "        for idx in range(len(C_list)-1):\n",
        "            mid_point.append((C_list[idx] + C_list[idx+1])/2)\n",
        "        collision_list = C_list + mid_point\n",
        "\n",
        "        self.C_list = [pos.reshape(2, 1) for pos in C_list]\n",
        "        self.collision_list = [pos.reshape(2, 1) for pos in collision_list]\n",
        "\n",
        "        # print(\"self.C_list: \",self.C_list)\n",
        "\n",
        "        self.min_area, self.max_area = fly_area\n",
        "        for i in range(2):\n",
        "            if self.min_area[i]>=self.max_area[i]:\n",
        "                print(\"[ERROR] min_area>max_area\")\n",
        "\n",
        "        path = tree_csv+\"/environment_\" + str(file_num) + \"/static_obstacles.csv\"\n",
        "        obstacle_x_list = []\n",
        "        obstacle_y_list = []\n",
        "        self.radius_list = []\n",
        "        with open(path) as f:\n",
        "            reader = csv.reader(f)\n",
        "            for row in reader:\n",
        "                obstacle_x_list.append(float(row[1]))\n",
        "                obstacle_y_list.append(float(row[2]))\n",
        "                self.radius_list.append(float(row[8]))\n",
        "        self.obstacle_kd_tree = KDTree(np.vstack((obstacle_x_list, obstacle_y_list)).T)\n",
        "        \n",
        "        self.add_range=[]\n",
        "        self.add_range.append(x_add_range)\n",
        "        self.add_range.append(y_add_range)\n",
        "        \n",
        "    def calc(self, init_pos: list, goal_pos: list, node_num:int):\n",
        "        # cample points\n",
        "        self.init_pos = init_pos\n",
        "        self.goal_pos = goal_pos\n",
        "        self.sample_points(init_pos, goal_pos, node_num)\n",
        "       \n",
        "        # show animation:\n",
        "        # color = [i for i in range(len(self.node_list))]\n",
        "        # sample_x = [node[0] for node in self.node_list]\n",
        "        # sample_y = [node[1] for node in self.node_list]\n",
        "        # fig = plt.figure(figsize = (10, 10))\n",
        "        # ax = fig.add_subplot(1,1,1)\n",
        "        # ax.scatter(sample_x, sample_y)\n",
        "        # for i in range(len(sample_x)):\n",
        "        #     plt.text(sample_x[i], sample_y[i],str(i))\n",
        "        # plt.show()\n",
        "\n",
        "        # sample_yaw = [node[2] for node in self.node_list]\n",
        "        # fig = plt.figure(figsize = (10, 10))\n",
        "        # ax = fig.add_subplot(1,1,1)\n",
        "        # ax.scatter(sample_x, sample_yaw)\n",
        "        # for i in range(len(sample_x)):\n",
        "        #     plt.text(sample_x[i], sample_yaw[i],str(i))\n",
        "        # plt.show()\n",
        "    \n",
        "    def collide(self, pos: list):\n",
        "        CoG_pos = np.array([pos[0],pos[1]])\n",
        "        CoG_pos.resize((2,1))\n",
        "        yaw = pos[2]\n",
        "        R = np.array([\n",
        "            [np.cos(yaw),-np.sin(yaw)],\n",
        "            [np.sin(yaw),np.cos(yaw)]\n",
        "            ])\n",
        "        for apex in self.collision_list:\n",
        "            apex = np.array(apex)\n",
        "            apex.resize((2,1))\n",
        "            # print(\"R.shape: \",R.shape)\n",
        "            # print(\"apex.shape: \",apex.shape)\n",
        "            t = CoG_pos+R@apex\n",
        "            tx = t[0,0]\n",
        "            ty = t[1,0]\n",
        "            dist, index = self.obstacle_kd_tree.query([tx, ty])\n",
        "            if len(self.radius_list)!=0 and dist <= self.radius_list[index]:\n",
        "                return True\n",
        "        return False\n",
        "    \n",
        "    def sample_points(self, init_pos: list, goal_pos: list, node_num:int):\n",
        "        min_range=[]\n",
        "        max_range=[]\n",
        "        for i in range(2):\n",
        "            if not ((self.min_area[i]<init_pos[i]-self.add_range[i]) and (self.min_area[i]<goal_pos[i]-self.add_range[i])):\n",
        "                print(\"min is out of range\")\n",
        "                min_range.append(self.min_area[i])\n",
        "            else:\n",
        "                min_range.append(min(init_pos[i]-self.add_range[i],goal_pos[i]-self.add_range[i]))\n",
        "            if not ((init_pos[i]+self.add_range[i]<self.max_area[i]) and (goal_pos[i]+self.add_range[i]<self.max_area[i])):\n",
        "                print(\"max is out of range\")\n",
        "                max_range.append(self.max_area[i])\n",
        "            else:\n",
        "                max_range.append(max(init_pos[i]+self.add_range[i],goal_pos[i]+self.add_range[i]))\n",
        "        self.node_list = []\n",
        "        for _ in range(node_num):\n",
        "            node_pos = [min_range[i]+(max_range[i]-min_range[i])*random.random() for i in range(2)]\n",
        "            node_pos.append(random.uniform(-np.pi, np.pi))\n",
        "            if not self.collide(node_pos):\n",
        "                self.node_list.append(node_pos)\n",
        "\n",
        "        if not self.collide(init_pos):\n",
        "            self.node_list.append(init_pos)\n",
        "        else:\n",
        "            raise InitCollisionError(\"init_pos is collide\")\n",
        "        \n",
        "        if not self.collide(goal_pos):\n",
        "            self.node_list.append(goal_pos)\n",
        "        else:\n",
        "            raise GoalCollisionError(\"goal_pos is collide\")\n",
        "    \n",
        "    def generate_road_map(self, rr=0): #rr is radius of robot\n",
        "        self.road_map = []\n",
        "        sample_x = [node[0] for node in self.node_list]\n",
        "        sample_y = [node[1] for node in self.node_list]\n",
        "        sample_yaw = [node[2]*self.yaw_weight for node in self.node_list] \n",
        "\n",
        "        n_sample = len(sample_x) #this num is different from node_num in calc, for this eliminates collide candidates\n",
        "        # Be careful, we didn\n",
        "        sample_kd_tree = KDTree(np.vstack((sample_x, sample_y,sample_yaw)).T) # this kd_tree is for connection between nodes\n",
        "\n",
        "\n",
        "        for (i, ix, iy,iyaw) in zip(range(n_sample), sample_x, sample_y,sample_yaw): #select one point from sample points\n",
        "\n",
        "            dists, indexes = sample_kd_tree.query([ix, iy,iyaw], k=n_sample) #sort from selected sample point\n",
        "            edge_id = []\n",
        "            true_iyaw = iyaw/self.yaw_weight #iyawは重み付けされたyawなので、実際のyawとは異なるため、正しいyawに戻す\n",
        "\n",
        "            for ii in range(1, len(indexes)): #nodes around given node\n",
        "                nx = sample_x[indexes[ii]]\n",
        "                ny = sample_y[indexes[ii]]\n",
        "                nyaw = sample_yaw[indexes[ii]]\n",
        "                true_nyaw = nyaw/self.yaw_weight\n",
        "\n",
        "                if not self.edge_collision(ix, iy, true_iyaw, nx, ny, true_nyaw, rr):\n",
        "                    edge_id.append(indexes[ii])\n",
        "\n",
        "                if len(edge_id) >= self.N_KNN:\n",
        "                    break\n",
        "            self.road_map.append(edge_id)\n",
        "\n",
        "    def edge_collision(self, sx, sy, syaw, gx, gy, gyaw, rr):\n",
        "        x = sx\n",
        "        y = sy\n",
        "        yaw = syaw\n",
        "        dx = gx - sx\n",
        "        dy = gy - sy\n",
        "        dyaw = gyaw - syaw\n",
        "        direction = np.array([dx, dy,dyaw])\n",
        "        d = np.linalg.norm(direction)\n",
        "        if d >= self.MAX_EDGE_LEN:\n",
        "            return True\n",
        "        direction = direction / d\n",
        "        # math.atan2(gy - sy, gx - sx)\n",
        "        D = max(rr,self.edge_l/2)\n",
        "        n_step = int(d / D) # n_step is the number of steps to reach goal point round down\n",
        "\n",
        "        for i in range(n_step):\n",
        "            pos = [x,y,yaw]\n",
        "            if self.collide(pos):\n",
        "                return True # collision\n",
        "            x += D * direction[0]\n",
        "            y += D * direction[1]\n",
        "            yaw += D * direction[2]\n",
        "        pos = [gx,gy,gyaw]\n",
        "        if self.collide(pos):\n",
        "            return True\n",
        "        return False  # OK\n",
        "\n",
        "    def edge_collision_deb(self, sx, sy, syaw, gx, gy, gyaw, rr):\n",
        "        x = sx\n",
        "        y = sy\n",
        "        yaw = syaw\n",
        "        dx = gx - sx\n",
        "        dy = gy - sy\n",
        "        dyaw = gyaw - syaw\n",
        "        direction = np.array([dx, dy,dyaw])\n",
        "        d = np.linalg.norm(direction)\n",
        "        if d >= self.MAX_EDGE_LEN:\n",
        "            return True\n",
        "        direction = direction / d\n",
        "        # math.atan2(gy - sy, gx - sx)\n",
        "        D = max(rr,self.edge_l/2)\n",
        "        n_step = int(d / D) # n_step is the number of steps to reach goal point round down\n",
        "        print(\"n_step\",n_step)\n",
        "\n",
        "        self.pos_deb = []\n",
        "\n",
        "        for i in range(n_step):\n",
        "            pos = [x,y,yaw]\n",
        "            print(\"i is\",i)\n",
        "            print(\"pos is \",pos)\n",
        "            self.pos_deb.append(pos)\n",
        "            if self.collide(pos):\n",
        "                return True # collision\n",
        "            x += D * direction[0]\n",
        "            y += D * direction[1]\n",
        "            yaw += D * direction[2]\n",
        "        pos = [gx,gy,gyaw]\n",
        "        print(\"pos is \",pos)\n",
        "        self.pos_deb.append(pos)\n",
        "        if self.collide(pos):\n",
        "            return True\n",
        "        return False  # OK\n",
        "\n",
        "    def dijkstra_planning(self) ->tuple:\n",
        "        \"\"\"\n",
        "        s_x: start x position [m]\n",
        "        s_y: start y position [m]\n",
        "        s_yaw: start yaw angle [rad]\n",
        "        goal_x: goal x position [m]\n",
        "        goal_y: goal y position [m]\n",
        "        goal_yaw: goal yaw angle [rad]\n",
        "        @return: Two lists of path coordinates ([x1, x2, ...], [y1, y2, ...],[yaw1, yaw2, ...]), empty list when no path was found\n",
        "        \"\"\"\n",
        "\n",
        "        start_node = Node(self.init_pos[0],self.init_pos[1],self.init_pos[2], 0.0, -1)\n",
        "        goal_node = Node(self.goal_pos[0],self.goal_pos[1], self.goal_pos[2], 0.0, -1)\n",
        "\n",
        "        open_set, closed_set = dict(), dict()\n",
        "        open_set[len(self.road_map) - 2] = start_node\n",
        "\n",
        "        path_found = True\n",
        "\n",
        "        while True:\n",
        "            if not open_set:\n",
        "                raise PathNotFoundError(\"Cannot find path\")\n",
        "                path_found = False\n",
        "                break\n",
        "\n",
        "            c_id = min(open_set, key=lambda o: open_set[o].cost)\n",
        "            current = open_set[c_id]\n",
        "\n",
        "            # show graph\n",
        "            # if self.show_animation and len(closed_set.keys()) % 2 == 0:\n",
        "            #     # for stopping simulation with the esc key.\n",
        "            #     plt.gcf().canvas.mpl_connect(\n",
        "            #         'key_release_event',\n",
        "            #         lambda event: [exit(0) if event.key == 'escape' else None])\n",
        "            #     plt.plot(current.x, current.y,current.yaw, \"xg\")\n",
        "            #     plt.pause(0.001)\n",
        "\n",
        "            if c_id == (len(self.road_map) - 1):\n",
        "                # print(\"goal is found!\")\n",
        "                goal_node.parent_index = current.parent_index\n",
        "                goal_node.cost = current.cost\n",
        "                break\n",
        "\n",
        "            # Remove the item from the open set\n",
        "            del open_set[c_id]\n",
        "            # Add it to the closed set\n",
        "            closed_set[c_id] = current\n",
        "\n",
        "            # expand search grid based on motion model\n",
        "            for i in range(len(self.road_map[c_id])):\n",
        "                n_id = self.road_map[c_id][i]\n",
        "                dx = self.node_list[n_id][0] - current.x\n",
        "                dy = self.node_list[n_id][1] - current.y\n",
        "                dyaw = self.node_list[n_id][2] - current.yaw\n",
        "                d = math.hypot(dx, dy,dyaw)\n",
        "                node = Node(self.node_list[n_id][0], self.node_list[n_id][1], self.node_list[n_id][2],\n",
        "                            current.cost + d, c_id)\n",
        "\n",
        "                if n_id in closed_set:\n",
        "                    continue\n",
        "                # Otherwise if it is already in the open set\n",
        "                if n_id in open_set:\n",
        "                    if open_set[n_id].cost > node.cost:\n",
        "                        open_set[n_id].cost = node.cost\n",
        "                        open_set[n_id].parent_index = c_id\n",
        "                else:\n",
        "                    open_set[n_id] = node\n",
        "\n",
        "        # generate final course\n",
        "        rx, ry, ryaw = [goal_node.x], [goal_node.y], [goal_node.yaw]\n",
        "        parent_index = goal_node.parent_index\n",
        "        while parent_index != -1:\n",
        "            n = closed_set[parent_index]\n",
        "            rx.append(n.x)\n",
        "            ry.append(n.y)\n",
        "            ryaw.append(n.yaw)\n",
        "            parent_index = n.parent_index\n",
        "\n",
        "        return rx, ry, ryaw\n",
        "    \n",
        "    def prm_planning(self, init_pos: list, goal_pos: list, node_num: int):\n",
        "        self.calc(init_pos=init_pos,goal_pos=goal_pos, node_num=node_num)\n",
        "        self.generate_road_map()\n",
        "        self.path_output = self.dijkstra_planning()\n",
        "        self.current_edge = len(self.path_output[0])-1 #最後のedgeから計算\n",
        "    \n",
        "    def forward(self, current_pos: list) -> np.array:\n",
        "        # calculate direction\n",
        "        if self.change_edge:\n",
        "            # print(\"current edge is \",self.current_edge)\n",
        "            direction = [self.path_output[0][self.current_edge-1] - self.path_output[0][self.current_edge], self.path_output[1][self.current_edge-1] - self.path_output[1][self.current_edge], self.path_output[2][self.current_edge-1] - self.path_output[2][self.current_edge]]\n",
        "            # print(\"edge's direction is \",direction)\n",
        "            # print(\"edge's beginning is \",[self.path_output[0][self.current_edge],self.path_output[1][self.current_edge],self.path_output[2][self.current_edge]])\n",
        "            # print(\"edge's end is \",[self.path_output[0][self.current_edge-1],self.path_output[1][self.current_edge-1],self.path_output[2][self.current_edge-1]])\n",
        "            \n",
        "            direction = np.array([direction[0], direction[1], direction[2]*self.yaw_weight])\n",
        "            direction_norm = np.linalg.norm(direction)\n",
        "            # print(\"direction_norm is \",direction_norm)\n",
        "            self.edge_left = direction_norm\n",
        "            direction = direction/direction_norm\n",
        "            # direction = np.array([direction[0], direction[1], direction[2]/self.yaw_weight])\n",
        "            self.change_edge = False\n",
        "            self.act = direction * self.act_norm\n",
        "            self.act = np.array([self.act[0], self.act[1], self.act[2]/self.yaw_weight])\n",
        "            # print(\"not last point's act is \",self.act)\n",
        "        else:\n",
        "            self.edge_left -= self.act_norm\n",
        "\n",
        "        if self.edge_left < self.act_norm:\n",
        "            # print(\"last point of edge\")\n",
        "            # print(\"current_pos is\",current_pos)\n",
        "            # print(\"self.edge_left is \",self.edge_left)\n",
        "            self.change_edge = True\n",
        "\n",
        "            direction = [self.path_output[0][self.current_edge-1] - current_pos[0], self.path_output[1][self.current_edge-1] - current_pos[1], self.path_output[2][self.current_edge-1] - current_pos[2]]\n",
        "            # print(\"act in last edge is \", direction)\n",
        "\n",
        "            self.act = np.array(direction)\n",
        "            if self.act_norm<np.linalg.norm(np.array([self.act[0],self.act[1],self.act[2]*self.yaw_weight])):\n",
        "                print(\"self.act is larger than self.act_norm\")\n",
        "            self.current_edge -= 1\n",
        "        return self.act\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     prm = Prm(robot_theta=[0,60,0],edge_l=0.6,fly_area=[[2,-5.0],[12,5.0]],tree_csv=\"/content/drive/MyDrive/先端人工知能論_プロジェクト/tree_folder\",file_num=499,x_add_range=2.0,y_add_range=2.0, act_norm = 0.1)\n",
        "#     path = prm.prm_planning(init_pos=[5.0,-1,0.1],goal_pos=[9.0,0,0], node_num=100)\n",
        "#     # prm.generate_road_map()\n",
        "#     print(prm.road_map)\n",
        "#     # prm.dijkstra_planning()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRMが問題なくうごているのか確認したところ、pathの接続がうまくいっていないことが判明\n",
        "\n",
        "\n",
        "バグはiyawなどの値がself.yaw_weight倍された値のまま衝突判定がされていたことが原因"
      ],
      "metadata": {
        "id": "nEyGaRen816a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.collections as mc\n",
        "from google.colab import files\n",
        "figure, axes = plt.subplots()\n",
        "\n",
        "def visualize(given_pos: list):\n",
        "    path = tree_csv+\"/environment_\" + str(file_num) + \"/static_obstacles.csv\"\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            x = float(row[1])\n",
        "            y = float(row[2])\n",
        "            r = float(row[8]) #+body_size\n",
        "            draw_circle = plt.Circle((x, y), r)\n",
        "            axes.add_artist(draw_circle)\n",
        "\n",
        "    CoG_pos = np.array([\n",
        "    [given_pos[0]],\n",
        "    [given_pos[1]]\n",
        "    ])\n",
        "    yaw = given_pos[2]\n",
        "    r = np.array([\n",
        "    [np.cos(yaw), -np.sin(yaw)],\n",
        "    [np.sin(yaw), np.cos(yaw)]\n",
        "        ])\n",
        "    # print(\"prm.C_list: \",prm.C_list)\n",
        "    edge_list = [CoG_pos + r @ pos for pos in prm.C_list]\n",
        "    # print(\"edge_list: \",edge_list)\n",
        "    lines = [[(edge_list[i][0,0],edge_list[i][1,0]),(edge_list[i+1][0,0],edge_list[i+1][1,0])]\n",
        "    for i in range(len(edge_list)-1)]\n",
        "    lc = mc.LineCollection(lines, colors = \"g\",linewidths=2)\n",
        "    axes.add_collection(lc)\n",
        "    print(\"fig_num: \" , fig_num)\n",
        "    plt.savefig(str(fig_num))\n",
        "    files.download(\"temp_figure\")\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,8))\n",
        "plt.xlim([-0.3, 12])\n",
        "plt.ylim([-5.0, 5.0])\n",
        "tree_csv = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/tree_folder\"\n",
        "file_num = 500\n",
        "fig_num:int = 0\n",
        "# global fig_num\n",
        "print(\"out of fig_num: \" , fig_num)\n",
        "\n",
        "# prmでの点での状態を確認\n",
        "x_list = prm.path_output[0]\n",
        "y_list = prm.path_output[1]\n",
        "yaw_list = prm.path_output[2]\n",
        "\n",
        "for x,y,yaw in zip(x_list,y_list,yaw_list):\n",
        "    visualize([x,y,yaw])\n",
        "# prm.path_output #明らかに障害物に衝突しそうなedgeが含まれている\n",
        "# idx = 3\n",
        "# prm.edge_collision_deb(prm.path_output[0][idx], prm.path_output[1][idx], prm.path_output[2][idx], prm.path_output[0][idx-1], prm.path_output[1][idx-1], prm.path_output[2][idx-1],0)\n",
        "# # True(collisionしている)ということになっているが、なぜかedgeに含まれている\n",
        "# prm.pos_deb"
      ],
      "metadata": {
        "id": "tdcrnPMl5D3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.collections as mc\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "figure, axes = plt.subplots()\n",
        "tree_csv = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/tree_folder\"\n",
        "plt.xlim([-2, 2])\n",
        "plt.ylim([-2, 2])\n",
        "path = tree_csv+\"/environment_\" + str(file_num) + \"/static_obstacles.csv\"\n",
        "CoG_pos = np.array([\n",
        "    [0],\n",
        "    [0]\n",
        "    ])\n",
        "yaw = 0\n",
        "r = np.array([\n",
        "[np.cos(yaw), -np.sin(yaw)],\n",
        "[np.sin(yaw), np.cos(yaw)]\n",
        "    ])\n",
        "# print(\"prm.C_list: \",prm.C_list)\n",
        "edge_list = [CoG_pos + r @ pos for pos in prm.C_list]\n",
        "# print(\"edge_list: \",edge_list)\n",
        "lines = [[(edge_list[i][0,0],edge_list[i][1,0]),(edge_list[i+1][0,0],edge_list[i+1][1,0])]\n",
        "for i in range(len(edge_list)-1)]\n",
        "lc = mc.LineCollection(lines, colors = \"g\",linewidths=2)\n",
        "axes.add_collection(lc)\n",
        "print(\"fig_num: \" , fig_num)\n",
        "plt.savefig(str(fig_num))\n",
        "# files.download(\"temp_figure\")"
      ],
      "metadata": {
        "id": "jg9bjAy-iY9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOyazSsamWI9"
      },
      "outputs": [],
      "source": [
        "class Cylinder:\n",
        "    max_dist = 10 #class variable\n",
        "    def __init__(self, x, y, radius):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.radius = radius\n",
        "\n",
        "    def calculate_depth(self, x, y, theta):\n",
        "        # 円柱との交点を計算する関数\n",
        "        def intersect(cx, cy, radius, x, y, theta)->float:\n",
        "            # (x, y)を原点とした座標系において、円柱の中心(cx, cy)を移動させる\n",
        "            cx -= x\n",
        "            cy -= y\n",
        "            # theta方向に移動させる\n",
        "            c, s = math.cos(-theta), math.sin(-theta)\n",
        "            cx, cy = cx * c - cy * s, cx * s + cy * c\n",
        "            # 交点を計算する\n",
        "            # a = cx**2 + cy**2\n",
        "            # b = 2 * (cx * x + cy * y)\n",
        "            # c = x**2 + y**2 - radius**2\n",
        "            # discriminant = b**2 - 4*a*c\n",
        "            discriminant = radius**2-cy**2\n",
        "            if discriminant < 0:\n",
        "                # 交点がない場合は、無限遠のdepthを返す\n",
        "                return self.max_dist\n",
        "            # t1 = (-b - math.sqrt(discriminant)) / (2 * a)\n",
        "            # # t1が0より小さい場合は、infを出力\n",
        "            t = cx - np.sqrt(discriminant)\n",
        "            if t < 0:\n",
        "                return self.max_dist\n",
        "            # t = t1\n",
        "            return t\n",
        "\n",
        "        # 交点方向の長さを計算\n",
        "        return intersect(self.x, self.y, self.radius, x, y, theta)\n",
        "\n",
        "    @classmethod\n",
        "    def calculate_depths(cls, cylinders: list, x, y, thetas:list)->list:\n",
        "        # thetasの要素ごとにdepthを計算する\n",
        "        if len(cylinders)==0:\n",
        "            return [cls.max_dist for theta in thetas]\n",
        "        else:\n",
        "            return [min([c.calculate_depth(x, y, theta) for c in cylinders]) for theta in thetas]\n",
        "class Env:\n",
        "    def __init__(self, robot_theta: list, edge_l: float, fly_area: list, tree_csv: str, file_num: int, init_pos: list,goal_pos: list, thetas: list):\n",
        "        self.yaw_weight = 2.0\n",
        "        self.goal_determine = 0.2\n",
        "        theta = [np.deg2rad(i) for i in robot_theta] # from deg to rad\n",
        "        bR2 = np.array([0.0,0.0])\n",
        "        bC2 = np.array([-edge_l/2,0.0])\n",
        "        bC2ToR1 = np.array([-edge_l/2*np.cos(theta[0]),edge_l/2*np.sin(theta[0])])\n",
        "        bR1 = bC2+bC2ToR1\n",
        "        bC1 = bC2+bC2ToR1*2\n",
        "        bC3 = np.array([edge_l/2,0.0])\n",
        "        bC3ToR3 = np.array([edge_l/2*np.cos(theta[1]),edge_l/2*np.sin(theta[1])])\n",
        "        bR3 = bC3+bC3ToR3\n",
        "        bC4 = bC3+bC3ToR3*2\n",
        "        bC4ToR4 = np.array([edge_l/2*np.cos(theta[1]+theta[2]),edge_l/2*np.sin(theta[1]+theta[2])])\n",
        "        bR4 = bC4+bC4ToR4\n",
        "        bC5 = bC4+bC4ToR4*2\n",
        "        CG = (bR1+bR2+bR3+bR4)/4\n",
        "        C_list = [bC1-CG,bC2-CG,bC3-CG,bC4-CG,bC5-CG]\n",
        "        self.C_list = [pos.reshape(2, 1) for pos in C_list]\n",
        "\n",
        "        self.thetas : list = [-theta for theta in reversed(thetas)] + thetas\n",
        "        \n",
        "        # print(\"self.C_list: \",self.C_list)\n",
        "\n",
        "        self.min_area, self.max_area = fly_area\n",
        "        for i in range(2):\n",
        "            if self.min_area[i]>=self.max_area[i]:\n",
        "                print(\"[ERROR] min_area>max_area\")\n",
        "\n",
        "        path = tree_csv+\"/environment_\" + str(file_num) + \"/static_obstacles.csv\"\n",
        "        self.obstacle_x_list = []\n",
        "        self.obstacle_y_list = []\n",
        "        self.radius_list = []\n",
        "        with open(path) as f:\n",
        "            reader = csv.reader(f)\n",
        "            self.cylinders = [Cylinder(float(row[1]),float(row[2]),float(row[8])) for row in reader]\n",
        "            # for row in reader:\n",
        "            #     self.obstacle_x_list.append(float(row[1]))\n",
        "            #     self.obstacle_y_list.append(float(row[2]))\n",
        "            #     self.radius_list.append(float(row[8]))\n",
        "        self.pos: np.array = np.array(init_pos)\n",
        "        self.goal_pos = np.array(goal_pos)\n",
        "        self.done = False\n",
        "\n",
        "    def step(self, action: np.array):\n",
        "        self.pos[0]+=action[0]\n",
        "        self.pos[1]+=action[1]\n",
        "        self.pos[2]+=action[2]\n",
        "        obs = self.calc_observation(self.pos)\n",
        "        self.done = self.is_terminate() #terminate data collection and begin to set new position, delete environment\n",
        "        return np.concatenate([self.pos, obs])\n",
        "\n",
        "    def calc_observation(self, pos: np.array):\n",
        "        depths:list = Cylinder.calculate_depths(self.cylinders, pos[0], pos[1], self.thetas)\n",
        "        return np.array(depths)\n",
        "    \n",
        "    def is_terminate(self):\n",
        "        check_pos = np.array([self.pos[0],self.pos[1],self.pos[2]*self.yaw_weight])\n",
        "        check_goal = np.array([self.goal_pos[0],self.goal_pos[1],self.goal_pos[2]*self.yaw_weight])\n",
        "        return np.linalg.norm(check_pos-check_goal)<self.goal_determine"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# debug: edgeの位置を変更するときにself.act_norm以上のactが出てきてしまっているため、変更\n",
        "if __name__ == \"__main__\":\n",
        "    # hyper parameters\n",
        "    robot_theta = [0,60,0]\n",
        "    edge_l = 0.6\n",
        "    fly_area=[[0,-5.0],[60,5.0]]\n",
        "    tree_csv=\"/content/drive/MyDrive/先端人工知能論_プロジェクト/tree_folder\"\n",
        "    x_add_range=2.0\n",
        "    y_add_range=2.0\n",
        "    thetas = [5,15,25,35,45,60,75,90,105,120,135,150,165]\n",
        "    thetas = [np.deg2rad(theta) for theta in thetas]\n",
        "    act_norm = 0.4\n",
        "    state_data = np.empty((0,3+len(thetas)*2), float)\n",
        "    act_data = np.empty((0,3),float)\n",
        "\n",
        "    CONNECTION_RETRY = 8\n",
        "\n",
        "    file_num = 500\n",
        "    # environment making\n",
        "    init_pos=[5.0,-1,0]\n",
        "    goal_pos=[10.0,0,0]\n",
        "    node_num=100\n",
        "    sample_data=True\n",
        "    for i in range(1, CONNECTION_RETRY + 1):\n",
        "        try:\n",
        "            prm = Prm(robot_theta = robot_theta, edge_l=edge_l, fly_area=fly_area ,tree_csv=tree_csv, file_num=file_num, x_add_range=x_add_range, y_add_range=y_add_range, act_norm = act_norm)\n",
        "            prm.prm_planning(init_pos=init_pos, goal_pos=goal_pos, node_num=node_num)\n",
        "        except InitCollisionError as e:\n",
        "            print(\"In\", file_num, \" start or goal is collide. retry:{i}/{max}\".format(i=i,max=CONNECTION_RETRY))\n",
        "            print(\"error type is \",str(type(e)))\n",
        "            init_pos = [pos + random.uniform(-0.3, 0.3) for pos in init_pos]\n",
        "            goal_pos = [pos + random.uniform(-0.3, 0.3) for pos in goal_pos]\n",
        "            if i==CONNECTION_RETRY:\n",
        "                sample_data=False\n",
        "        except GoalCollisionError as e:\n",
        "            print(\"In\", file_num, \" start or goal is collide. retry:{i}/{max}\".format(i=i,max=CONNECTION_RETRY))\n",
        "            print(\"error type is \",str(type(e)))\n",
        "            init_pos = [pos + random.uniform(-0.3, 0.3) for pos in init_pos]\n",
        "            goal_pos = [pos + random.uniform(-0.3, 0.3) for pos in goal_pos]\n",
        "            if i==CONNECTION_RETRY:\n",
        "                sample_data=False\n",
        "        except PathNotFoundError as e:\n",
        "            print(\"In\", file_num, \"path is not found. retry:{i}/{max}\".format(i=i,max=CONNECTION_RETRY))\n",
        "            print(\"error type is \",str(type(e)))\n",
        "            node_num+=100\n",
        "            if i==CONNECTION_RETRY:\n",
        "                sample_data=False\n",
        "        else:\n",
        "            break\n",
        "    env = Env(robot_theta = robot_theta, edge_l=edge_l, fly_area=fly_area, tree_csv=tree_csv, file_num=file_num, init_pos=init_pos, goal_pos=goal_pos, thetas=thetas)\n",
        "\n",
        "    # running environment and collecting data\n",
        "    pos = init_pos\n",
        "    act = prm.forward(pos)\n",
        "    # print(\"prm.current_edge is :\",prm.current_edge)\n",
        "    new_obs = env.step(act)\n",
        "\n",
        "    while not env.is_terminate():\n",
        "        # state_data = np.hstack([state_data, new_obs])\n",
        "        state_data = np.append(state_data, new_obs.reshape(1,-1), axis=0)\n",
        "        act = prm.forward(pos)\n",
        "        act_data = np.append(act_data, act.reshape(1,-1), axis=0)\n",
        "        new_obs = env.step(act)\n",
        "        pos = env.pos\n",
        "    print(file_num,\" is done\")\n",
        "    np.savetxt(\"/content/drive/MyDrive/先端人工知能論_プロジェクト/自作データ/state_data/\"+\"case_\"+str(file_num)+\".csv\", state_data, delimiter=',', fmt='%.5e')\n",
        "    np.savetxt(\"/content/drive/MyDrive/先端人工知能論_プロジェクト/自作データ/act_data/\"+\"case_\"+str(file_num)+'.csv', act_data, delimiter=',', fmt='%.5e')\n",
        "        \n",
        "    # 最初はダミーデータが入るため、消去\n",
        "    state_data = state_data[1:]\n",
        "    act_data = act_data[1:]"
      ],
      "metadata": {
        "id": "R7QUIh4uo0xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prm.path_output"
      ],
      "metadata": {
        "id": "m_MhoXMi7V2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_last_act = np.array( [0.36680185, 0.06338815, 0.14641838])\n",
        "edge_direction = np.array([1.3053784807749391, 0.2255864491762989, 0.5210753372568608])\n",
        "edge_beginning = np.array( [5.046473912148123, -1.3813197721636434, 0.14773693680920624])\n",
        "current_pos = edge_beginning\n",
        "for _ in range(6):\n",
        "    # edge_direction-=non_last_act\n",
        "    current_pos += non_last_act\n",
        "    # print(\"edge_direction\",edge_direction)\n",
        "    print(\"current_pos\",current_pos)"
      ],
      "metadata": {
        "id": "au6x0na_4TR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmVfOfHCJ7Ja"
      },
      "outputs": [],
      "source": [
        "# visualize start to goal for debug\n",
        "figure, axes = plt.subplots()\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,8))\n",
        "plt.xlim([-0.3, 12])\n",
        "plt.ylim([-5.0, 5.0])\n",
        "tree_csv = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/tree_folder\"\n",
        "file_num = 500\n",
        "fig_num:int = 0\n",
        "# global fig_num\n",
        "print(\"out of fig_num: \" , fig_num)\n",
        "\n",
        "for data in state_data[::5]:\n",
        "    visualize([data[0],data[1],data[2]])\n",
        "    fig_num+=5\n",
        "\n",
        "\n",
        "# data = state_data[0]\n",
        "# visualize([data[0],data[1],data[2]])\n",
        "# fig_num+=1\n",
        "\n",
        "# visualize([7.970126625404299,-0.895266442631526,-0.008050072924890461])\n",
        "# visualize([5.0,-1,0])\n",
        "# visualize(prm.node_list[36])\n",
        "# It should be connected between 43 and 84 in this situation..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prm.path_output"
      ],
      "metadata": {
        "id": "E3_LfU0V4eje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3xPEOYSm_Li"
      },
      "outputs": [],
      "source": [
        "# 一つの環境で環境を入手して、そのstepでの学習結果の取得を行う\n",
        "if __name__ == \"__main__\":\n",
        "    # hyper parameters\n",
        "    robot_theta = [0,60,0]\n",
        "    edge_l = 0.6\n",
        "    fly_area=[[0,-5.0],[60,5.0]]\n",
        "    tree_csv=\"/content/drive/MyDrive/先端人工知能論_プロジェクト/tree_folder\"\n",
        "    x_add_range=2.0\n",
        "    y_add_range=2.0\n",
        "    thetas = [5,15,25,35,45,60,75,90,105,120,135,150,165]\n",
        "    thetas = [np.deg2rad(theta) for theta in thetas]\n",
        "    act_norm = 1.5\n",
        "\n",
        "    CONNECTION_RETRY = 8\n",
        "\n",
        "    for file_num in reversed(range(501)):\n",
        "        state_data = np.empty((0,3+len(thetas)*2), float)\n",
        "        act_data = np.empty((0,3),float)\n",
        "        # reset state_data, act_data when changeing different envirioment\n",
        "        # environment making\n",
        "        init_pos=[5.0,-1,0]\n",
        "        goal_pos=[55.0,0,0]\n",
        "        node_num=100\n",
        "        sample_data=True\n",
        "        for i in range(1, CONNECTION_RETRY + 1):\n",
        "            try:\n",
        "                prm = Prm(robot_theta = robot_theta, edge_l=edge_l, fly_area=fly_area ,tree_csv=tree_csv, file_num=file_num, x_add_range=x_add_range, y_add_range=y_add_range, act_norm = act_norm)\n",
        "                prm.prm_planning(init_pos=init_pos, goal_pos=goal_pos, node_num=node_num)\n",
        "            except InitCollisionError as e:\n",
        "                print(\"In\", file_num, \" start or goal is collide. retry:{i}/{max}\".format(i=i,max=CONNECTION_RETRY))\n",
        "                print(\"error type is \",str(type(e)))\n",
        "                init_pos = [pos + random.uniform(-0.3, 0.3) for pos in init_pos]\n",
        "                if i==CONNECTION_RETRY:\n",
        "                    sample_data=False\n",
        "            except GoalCollisionError as e:\n",
        "                print(\"In\", file_num, \" start or goal is collide. retry:{i}/{max}\".format(i=i,max=CONNECTION_RETRY))\n",
        "                print(\"error type is \",str(type(e)))\n",
        "                goal_pos = [pos + random.uniform(-0.3, 0.3) for pos in goal_pos]\n",
        "                if i==CONNECTION_RETRY:\n",
        "                    sample_data=False\n",
        "            except PathNotFoundError as e:\n",
        "                print(\"In\", file_num, \"path is not found. retry:{i}/{max}\".format(i=i,max=CONNECTION_RETRY))\n",
        "                print(\"error type is \",str(type(e)))\n",
        "                node_num+=100\n",
        "                if i==CONNECTION_RETRY:\n",
        "                    sample_data=False\n",
        "            else:\n",
        "                break\n",
        "        if not sample_data:\n",
        "            continue\n",
        "        env = Env(robot_theta = robot_theta, edge_l=edge_l, fly_area=fly_area, tree_csv=tree_csv, file_num=file_num, init_pos=init_pos, goal_pos=goal_pos, thetas=thetas)\n",
        "\n",
        "        # running environment and collecting data\n",
        "        pos = init_pos\n",
        "        act = prm.forward(pos)\n",
        "        # print(\"prm.current_edge is :\",prm.current_edge)\n",
        "        new_obs = env.step(act)\n",
        "\n",
        "        while not env.is_terminate():\n",
        "            # state_data = np.hstack([state_data, new_obs])\n",
        "            state_data = np.append(state_data, new_obs.reshape(1,-1), axis=0)\n",
        "            act = prm.forward(pos)\n",
        "            act_data = np.append(act_data, act.reshape(1,-1), axis=0)\n",
        "            new_obs = env.step(act)\n",
        "            pos = env.pos\n",
        "        print(file_num,\" is done\")\n",
        "        # 最初はダミーデータが入るため、消去\n",
        "        state_data = state_data[1:]\n",
        "        act_data = act_data[1:]\n",
        "        np.savetxt(\"/content/drive/MyDrive/先端人工知能論_プロジェクト/自作データ/state_data/\"+\"case_\"+str(file_num)+\".csv\", state_data, delimiter=',', fmt='%.5e')\n",
        "        np.savetxt(\"/content/drive/MyDrive/先端人工知能論_プロジェクト/自作データ/act_data/\"+\"case_\"+str(file_num)+'.csv', act_data, delimiter=',', fmt='%.5e')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhDz-BEUeR7-"
      },
      "outputs": [],
      "source": [
        "x = np.arange(8).reshape(1,-1)\n",
        "print(x)\n",
        "##[[0, 1, 2, 3],\n",
        "##[4, 5, 6, 7]]\n",
        "\n",
        "# y = np.arange(9, 17).reshape(2,4)\n",
        "# print(y)\n",
        "# ##[[ 9, 10, 11],\n",
        "# ##[12, 13, 14]]\n",
        "\n",
        "# x_add = np.append(x,y,axis=0)\n",
        "# print(x_add)\n",
        "# ##[[ 0,  1,  2,  3],\n",
        "# ##[ 4,  5,  6,  7],\n",
        "# ##[ 9, 10, 11, 12],\n",
        "# ##[13, 14, 15, 16]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2lZNYfBo1Nw"
      },
      "outputs": [],
      "source": [
        "# 円柱を作成する\n",
        "c1 = Cylinder(4, 2, 1)\n",
        "c2 = Cylinder(2, 0, 1)\n",
        "c3 = Cylinder(4, 0, 1)\n",
        "\n",
        "# 円柱のリストを作成する\n",
        "cylinders = [c1,c2,c3]\n",
        "\n",
        "# 見たい位置のx座標、y座標、theta方向のリストを指定する\n",
        "x = 2\n",
        "y = 2\n",
        "thetas = [0, math.pi / 2, math.pi, math.pi * 3 / 2]\n",
        "\n",
        "# depthsを計算する\n",
        "depths = Cylinder.calculate_depths(cylinders, x, y, thetas)\n",
        "print(depths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PbpOdh8lq2B"
      },
      "outputs": [],
      "source": [
        "str(fig_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqMKIqwuaNnf"
      },
      "outputs": [],
      "source": [
        "visualize([9.0,0,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CwnGqgyNHVZ"
      },
      "outputs": [],
      "source": [
        "state_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxDMsGZDuELt"
      },
      "outputs": [],
      "source": [
        "ii=1\n",
        "nx = sample_x[indexes[ii]]\n",
        "ny = sample_y[indexes[ii]]\n",
        "nyaw = sample_yaw[indexes[ii]]\n",
        "\n",
        "print(prm.edge_collision(sample_x[-2], sample_y[-2], sample_yaw[-2], nx, ny, nyaw, 0)) #79と36はcollideしている"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnGCyuPxvIDr"
      },
      "outputs": [],
      "source": [
        "CoG_pos = np.array([pos[0],pos[1]])\n",
        "CoG_pos.resize((2,1))\n",
        "yaw = pos[2]\n",
        "R = np.array([\n",
        "    [np.cos(yaw),-np.sin(yaw)],\n",
        "    [np.sin(yaw),np.cos(yaw)]\n",
        "    ])\n",
        "for apex in self.C_list:\n",
        "    apex = np.array(apex)\n",
        "    apex.resize((2,1))\n",
        "    # print(\"R.shape: \",R.shape)\n",
        "    # print(\"apex.shape: \",apex.shape)\n",
        "    t = CoG_pos+R@apex\n",
        "    tx = t[0,0]\n",
        "    ty = t[1,0]\n",
        "    dist, index = self.obstacle_kd_tree.query([tx, ty])\n",
        "    if len(self.radius_list)!=0 and dist <= self.radius_list[index]:\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "state_data,act_dataファイルをもとに学習を行う"
      ],
      "metadata": {
        "id": "OIZICsCZ_fiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#作成したファイルを一つのcavファイルにまとめる\n",
        "\n",
        " \n",
        "file_path = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/自作データ/state_data/\"\n",
        "csv_files = glob.glob(file_path + '/*')\n",
        "\n",
        "for a in csv_files:\n",
        "    print(a)\n",
        "\n",
        "#csvファイルの中身を追加していくリストを用意\n",
        "data_list = []\n",
        "\n",
        "#読み込むファイルのリストを走査\n",
        "for file in csv_files:\n",
        "    data_list.append(pd.read_csv(file,header=None))\n",
        "\n",
        "#リストを全て行方向に結合\n",
        "#axis=0:行方向に結合, sort\n",
        "df = pd.concat(data_list, axis=0,ignore_index=True, sort=True)\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/先端人工知能論_プロジェクト/自作データ/state_data/whole_data.csv\",index=False)"
      ],
      "metadata": {
        "id": "Fth3PwrL_wAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "    print('Not using a high-RAM runtime')\n",
        "else:\n",
        "    print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "63-tvIOvZB2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "whole_data.csvファイルをもとにobsからactを出力させるデータを作成する\n",
        "(本来であれば、trajの近さを考えて、学習を考えてみる必要もあるとは思った(cf. Deep-PANTHER Planner))\n",
        "\n",
        "ただし、\"Learning Perception-aware Agile Flight in Cluttered Environments\"では、このような工夫がされずに学習が行われていた"
      ],
      "metadata": {
        "id": "kag9iwHRY71t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# csvファイルをシャッフル\n",
        "x_df = pd.read_csv(\"/content/drive/MyDrive/先端人工知能論_プロジェクト/自作データ/state_data/whole_data.csv\",header=None)\n",
        "y_df = pd.read_csv(\"/content/drive/MyDrive/先端人工知能論_プロジェクト/自作データ/act_data/whole_data.csv\",header=None)\n",
        "teacher_df = pd.concat([x_df, y_df], axis=1,ignore_index=True) #横結合(cf. https://datasciencemore.com/python-pandas-concat/)\n",
        "teacher_df = teacher_df.sample(frac=1) #データシャッフル(cf. https://note.nkmk.me/python-pandas-random-sort-shuffle/)\n",
        "\n",
        "# 教師データ,テストデータの分割\n",
        "train, test = train_test_split(teacher_df, test_size=0.1)\n",
        "\n",
        "# pandas to numpy data (cf. https://dreamer-uma.com/pytorch-dataset/)\n",
        "x_train = torch.FloatTensor(train.loc[:,:3+len(thetas)*2-1].values)\n",
        "y_train = torch.FloatTensor(train.loc[:,3+len(thetas)*2:].values)\n",
        "x_test = torch.FloatTensor(test.loc[:,:3+len(thetas)*2-1].values)\n",
        "y_test = torch.FloatTensor(test.loc[:,3+len(thetas)*2:].values)\n",
        "# x_df, y_df　のデータ結合に変更"
      ],
      "metadata": {
        "id": "2DORQvawd39h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_df)"
      ],
      "metadata": {
        "id": "OPKpZ8GBQZ23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[:,:3]"
      ],
      "metadata": {
        "id": "4QtbPN4fmXKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ref: https://qiita.com/sudamasahiko/items/b54fed1ffe8bb6d48818 https://learn.microsoft.com/ja-jp/windows/ai/windows-ml/tutorials/pytorch-train-model\n",
        "# ref: network 関係でsuper内で自身のnetworkの名前は省略可能 https://tzmi.hatenablog.com/entry/2019/12/31/002627"
      ],
      "metadata": {
        "id": "0rStmvG_DkzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo\n",
        "# 単純に全てのobsをNNに突っ込む\n",
        "\n",
        "# Define a convolution neural network\n",
        "batchsize = 100\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(3+len(thetas)*2, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 3)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = F.relu(self.fc1(input))\n",
        "        output = F.relu(self.fc2(output))    \n",
        "        output = F.relu(self.fc3(output))                        \n",
        "        output = F.relu(self.fc4(output))\n",
        "        return output\n",
        "\n",
        "# Instantiate a neural network model \n",
        "model = Network()"
      ],
      "metadata": {
        "id": "id5A0LpaytUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def saveModel():\n",
        "    path = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/learned_model.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def train(num_epochs):\n",
        "    \n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "\n",
        "    test_n = x_train.shape[0] # test_num\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i in range(0, test_n, batchsize):\n",
        "            x = x_train[i: i+batchsize]\n",
        "            y = y_train[i: i+batchsize]\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(x)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, y)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 1,000 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i/batchsize % 100 == 99:    \n",
        "                # print every 1000 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "        saveModel()\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "    # Let's build our model\n",
        "    train(20)"
      ],
      "metadata": {
        "id": "Fcm-Hfl6gxxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obsの情報をNNで次元圧縮してから学習に突っ込む\n",
        "class Vision_network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.obs1 = nn.Linear(len(thetas)*2, 256)\n",
        "        self.obs2 = nn.Linear(256, 512)\n",
        "        self.obs3 = nn.Linear(512, 512)\n",
        "        self.obs4 = nn.Linear(512, 256)\n",
        "        self.obs5 = nn.Linear(256, 128)\n",
        "        self.obs6 = nn.Linear(128, 32)\n",
        "        self.obs7 = nn.Linear(32, 8)\n",
        "        self.fc1 = nn.Linear(3+8, 16)\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc3 = nn.Linear(16, 8)\n",
        "        self.fc4 = nn.Linear(8, 3)\n",
        "\n",
        "    def forward(self, input):\n",
        "        pos = input[:,:3]\n",
        "        obs = input[:,3:]\n",
        "        obs = F.relu(self.obs1(obs))\n",
        "        obs = F.relu(self.obs2(obs))\n",
        "        obs = F.relu(self.obs3(obs))\n",
        "        obs = F.relu(self.obs4(obs))\n",
        "        obs = F.relu(self.obs5(obs))\n",
        "        obs = F.relu(self.obs6(obs))\n",
        "        obs = F.relu(self.obs7(obs))\n",
        "        output = torch.cat([pos, obs],axis=1)\n",
        "        output = F.relu(self.fc1(output))\n",
        "        output = F.relu(self.fc2(output))    \n",
        "        output = F.relu(self.fc3(output))                        \n",
        "        output = F.relu(self.fc4(output))\n",
        "        return output\n",
        "model = Vision_network()"
      ],
      "metadata": {
        "id": "YTruQuHtDNnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "loss_calcularion_interval: int = 100 #how often you print running_loss\n",
        "batchsize = 100\n",
        "\n",
        "def saveModel():\n",
        "    path = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/learned_model.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def train(num_epochs):\n",
        "    \n",
        "    # best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "\n",
        "    test_n = x_train.shape[0] # test_num\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i in range(0, test_n, batchsize):\n",
        "            x = x_train[i: i+batchsize]\n",
        "            y = y_train[i: i+batchsize]\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(x)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, y)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 1,000 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i/batchsize % loss_calcularion_interval == loss_calcularion_interval-1:    \n",
        "                # print every 1000 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.5f' %\n",
        "                      (epoch + 1, i + 1, running_loss/loss_calcularion_interval))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "    saveModel()\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "    # Let's build our model\n",
        "    train(20)"
      ],
      "metadata": {
        "id": "rdVmsPsYnLVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_calcularion_interval: int = 10\n",
        "\n",
        "def eval():\n",
        "    test_n = x_test.shape[0] # test_num\n",
        "    running_loss = 0.0\n",
        "    for i in range(0, test_n, batchsize):\n",
        "        x = x_test[i: i+batchsize]\n",
        "        y = y_test[i: i+batchsize]\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # predict classes using images from the training set\n",
        "        outputs = model(x)\n",
        "        # compute the loss based on model output and real labels\n",
        "        loss = loss_fn(outputs, y)\n",
        "        # backpropagate the loss\n",
        "        loss.backward()\n",
        "        # adjust parameters based on the calculated gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Let's print statistics for every 1,000 images\n",
        "        running_loss += loss.item()     # extract the loss value\n",
        "        if i/batchsize % loss_calcularion_interval == loss_calcularion_interval-1:    \n",
        "            # print every 1000 (twice per epoch) \n",
        "            print('[%5d] loss: %.5f' %\n",
        "                    (i + 1, running_loss/loss_calcularion_interval))\n",
        "            # zero the loss\n",
        "            running_loss = 0.0\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "    # Let's build our model\n",
        "    eval()"
      ],
      "metadata": {
        "id": "kBUuU_e1nLyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1dim-CNNを使用して、obsの次元を落とす"
      ],
      "metadata": {
        "id": "_pAsFuJW0sPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# この記事を参考にして、kernelを奇数にした https://blog.shikoan.com/pytorch-convtranspose2d/\n",
        "flatten = nn.Flatten(1, -1)\n",
        "class CNN_1dim(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.obs1 = nn.Conv1d(1,8,3,stride=1)\n",
        "        # shape: [channel, length_signal] = [1,len(thetas)*2 (= 26)] -> [8,24]\n",
        "        self.obs2 = nn.Conv1d(8,32,2,stride=1)\n",
        "        # [8,24] -> [32,23]\n",
        "        self.obs3 = nn.Conv1d(32,128,3,stride=1)\n",
        "        # [32,23] -> [128,21]\n",
        "        self.obs4 = nn.Conv1d(128,128,3,stride=2)\n",
        "        # [128,21] -> [128,10]\n",
        "        self.obs5 = nn.Conv1d(128,32,3,stride=1)\n",
        "        # [32,10] -> [32,8]\n",
        "        self.obs6 = nn.Conv1d(32,8,3,stride=1)\n",
        "        # [32,8] -> [8,6]\n",
        "        self.obs7 = nn.Conv1d(8,2,3,stride=1)\n",
        "        # [8,6] -> [2,4] = 8次元 \n",
        "        self.fc1 = nn.Linear(3+8, 16)\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc3 = nn.Linear(16, 8)\n",
        "        self.fc4 = nn.Linear(8, 3)\n",
        "\n",
        "    def forward(self, input):\n",
        "        pos = input[:,:3]\n",
        "        obs = input[:,3:]\n",
        "        obs = obs.unsqueeze(1)\n",
        "        obs = F.relu(self.obs1(obs))\n",
        "        obs = F.relu(self.obs2(obs))\n",
        "        obs = F.relu(self.obs3(obs))\n",
        "        obs = F.relu(self.obs4(obs))\n",
        "        obs = F.relu(self.obs5(obs))\n",
        "        obs = F.relu(self.obs6(obs))\n",
        "        obs = F.relu(self.obs7(obs))\n",
        "        obs = obs.view(-1,  self.num_flat_features(obs))\n",
        "\n",
        "        output = torch.cat([pos, obs],axis=1)\n",
        "        output = F.relu(self.fc1(output))\n",
        "        output = F.relu(self.fc2(output))    \n",
        "        output = F.relu(self.fc3(output))                        \n",
        "        output = F.relu(self.fc4(output))\n",
        "        return output\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "model = CNN_1dim()"
      ],
      "metadata": {
        "id": "uV1PPcua09O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "loss_calcularion_interval: int = 100 #how often you print running_loss\n",
        "batchsize = 100\n",
        "\n",
        "def saveModel():\n",
        "    path = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/learned_model.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def train(num_epochs):\n",
        "    \n",
        "    # best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "\n",
        "    test_n = x_train.shape[0] # test_num\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i in range(0, test_n, batchsize):\n",
        "            x = x_train[i: i+batchsize]\n",
        "            y = y_train[i: i+batchsize]\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(x)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, y)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 1,000 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i/batchsize % loss_calcularion_interval == loss_calcularion_interval-1:    \n",
        "                # print every 1000 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.5f' %\n",
        "                      (epoch + 1, i + 1, running_loss/loss_calcularion_interval))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "    saveModel()\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "    # Let's build our model\n",
        "    train(20)"
      ],
      "metadata": {
        "id": "Ll3l7m5ALVoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_calcularion_interval: int = 10\n",
        "eval()"
      ],
      "metadata": {
        "id": "VlNJPZ0aXinG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " x = x_train[0: 0+batchsize]\n",
        " x.shape"
      ],
      "metadata": {
        "id": "JOWpGgG6MY7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.unsqueeze(1)\n",
        "x.shape"
      ],
      "metadata": {
        "id": "5EEDtZVyP8p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_all = nn.Flatten(1, -1)\n",
        "flatten_all(x).shape"
      ],
      "metadata": {
        "id": "V9kHig2hQfWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Conv1d(16, 33, 3, stride=2)\n",
        "input = torch.randn(20, 16, 50)\n",
        "output = m(input)\n",
        "output.shape"
      ],
      "metadata": {
        "id": "MEMJa_jnDQac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def encode_dim(L_in,kernel_size,stride):\n",
        "    return math.floor((L_in-1*(kernel_size-1)-1)/stride+1)"
      ],
      "metadata": {
        "id": "sqDF9ssBF7P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encode1 = nn.Conv1d(1,8,3,stride=1)\n",
        "        # shape: [channel, length_signal] = [1,len(thetas)*2 (= 26)] -> [8,24]\n",
        "        self.encode2 = nn.Conv1d(8,32,2,stride=1)\n",
        "        # [8,24] -> [32,23]\n",
        "        self.encode3 = nn.Conv1d(32,128,3,stride=1)\n",
        "        # [32,23] -> [128,21]\n",
        "        self.encode4 = nn.Conv1d(128,128,3,stride=2)\n",
        "        # [128,21] -> [128,10]\n",
        "        self.encode5 = nn.Conv1d(128,32,3,stride=1)\n",
        "        # [128,10] -> [32,8]\n",
        "        self.encode6 = nn.Conv1d(32,8,3,stride=1)\n",
        "        # [32,8] -> [8,6]\n",
        "        self.encode7 = nn.Conv1d(8,2,3,stride=1)\n",
        "        # [8,6] -> [2,4] = 8次元 \n",
        "\n",
        "    def forward(self, obs):\n",
        "        obs = obs.unsqueeze(1)\n",
        "        obs = F.relu(self.encode1(obs))\n",
        "        obs = F.relu(self.encode2(obs))\n",
        "        obs = F.relu(self.encode3(obs))\n",
        "        obs = F.relu(self.encode4(obs))\n",
        "        obs = F.relu(self.encode5(obs))\n",
        "        obs = F.relu(self.encode6(obs))\n",
        "        obs = F.relu(self.encode7(obs))\n",
        "        # flattenしていない値をencoderの出力とした\n",
        "        return obs\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.decode7 = nn.ConvTranspose1d(2,8, kernel_size = 3 ,stride=1)\n",
        "        # shape: [channel, length_signal] = [2,4] -> [8,6]\n",
        "        self.decode6 = nn.ConvTranspose1d(8,32,kernel_size = 3 ,stride=1)\n",
        "        # [8,6] -> [32,8]\n",
        "        self.decode5 = nn.ConvTranspose1d(32,128, kernel_size = 3 ,stride=1)\n",
        "        # [32,8] -> [128,10]\n",
        "        self.decode4 = nn.ConvTranspose1d(128,128, kernel_size = 4 ,stride=2)\n",
        "        # [128,10] -> [128,22]\n",
        "        self.decode3 = nn.ConvTranspose1d(128,16, kernel_size = 3 ,stride=1)\n",
        "        # [128,22] -> [16,24]\n",
        "        self.decode2 = nn.ConvTranspose1d(16,1, kernel_size = 3 ,stride=1)\n",
        "        # [16,24] -> [1,26]\n",
        "\n",
        "    def forward(self, obs):\n",
        "        obs = F.relu(self.decode7(obs))\n",
        "        obs = F.relu(self.decode6(obs))\n",
        "        obs = F.relu(self.decode5(obs))\n",
        "        obs = F.relu(self.decode4(obs))\n",
        "        obs = F.relu(self.decode3(obs))\n",
        "        obs = F.relu(self.decode2(obs))\n",
        "        encode = obs.squeeze()\n",
        "        return encode\n",
        "\n",
        "# このサイトをもとに、AutoEncoder2クラスを作成https://atmarkit.itmedia.co.jp/ait/articles/2007/31/news025.html\n",
        "class AutoEncoder2(nn.Module):\n",
        "    def __init__(self, enc, dec):\n",
        "        super().__init__()\n",
        "        self.enc = enc\n",
        "        self.dec = dec\n",
        "    def forward(self, x):\n",
        "        x = self.enc(x)\n",
        "        x = self.dec(x)\n",
        "        return x\n",
        "\n",
        "encoder = Encoder()\n",
        "decoder = Decoder()\n",
        "model = AutoEncoder2(encoder, decoder)"
      ],
      "metadata": {
        "id": "HQg0XxQ5T_oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "NuzxeYkLkNK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def decode_dim(L_in,kernel_size,stride):\n",
        "    return (L_in-1)*stride+kernel_size"
      ],
      "metadata": {
        "id": "gvWsoA6vccBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode_dim(24,3,1)"
      ],
      "metadata": {
        "id": "rDnd-_5Xc2I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "loss_calcularion_interval: int = 100 #how often you print running_loss\n",
        "batchsize = 100\n",
        "\n",
        "def saveModel():\n",
        "    path = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/auto_encoder.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def train(num_epochs):\n",
        "    \n",
        "    # best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "\n",
        "    test_n = x_train.shape[0] # test_num\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i in range(0, test_n, batchsize):\n",
        "            x = x_train[i: i+batchsize]\n",
        "            true_obs = x[:,3:]\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(true_obs)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, true_obs)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 1,000 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i/batchsize % loss_calcularion_interval == loss_calcularion_interval-1:    \n",
        "                # print every 1000 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.5f' %\n",
        "                      (epoch + 1, i + 1, running_loss/loss_calcularion_interval))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "    saveModel()\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "    # Let's build our model\n",
        "    train(15)"
      ],
      "metadata": {
        "id": "Tu9g5kj2iygA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_calcularion_interval: int = 10\n",
        "\n",
        "def eval():\n",
        "    test_n = x_test.shape[0] # test_num\n",
        "    running_loss = 0.0\n",
        "    for i in range(0, test_n, batchsize):\n",
        "        x = x_train[i: i+batchsize]\n",
        "        true_obs = x[:,3:]\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # predict classes using images from the training set\n",
        "        outputs = model(true_obs)\n",
        "        # compute the loss based on model output and real labels\n",
        "        loss = loss_fn(outputs, true_obs)\n",
        "        # backpropagate the loss\n",
        "        # loss.backward()\n",
        "        # adjust parameters based on the calculated gradients\n",
        "        # optimizer.step()\n",
        "\n",
        "        # Let's print statistics for every 1,000 images\n",
        "        running_loss += loss.item()     # extract the loss value\n",
        "        if i/batchsize % loss_calcularion_interval == loss_calcularion_interval-1:    \n",
        "            # print every 1000 (twice per epoch) \n",
        "            print('[%5d] loss: %.5f' %\n",
        "                    (i + 1, running_loss/loss_calcularion_interval))\n",
        "            # zero the loss\n",
        "            running_loss = 0.0\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "    # Let's build our model\n",
        "    eval()\n",
        "# Auto-encoderは学習がうまくいっていることが確認できた"
      ],
      "metadata": {
        "id": "FL72VtXz2EuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load only encoder\n",
        "def loadEncoder():\n",
        "    path = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/auto_encoder.pth\"\n",
        "    encoder = Encoder()\n",
        "    decoder = Decoder()\n",
        "    model = AutoEncoder2(encoder, decoder)\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    # modelのparameterの変更をなくすため\n",
        "    # https://tips-memo.com/pytorch-parameters-stop\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False \n",
        "    return model.enc\n",
        "# encoder = loadEncoder()\n",
        "\n",
        "class CNN_2dim(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = loadEncoder()\n",
        "        self.fc1 = nn.Linear(3+8, 16)\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc3 = nn.Linear(16, 8)\n",
        "        self.fc4 = nn.Linear(8, 3)\n",
        "\n",
        "    def forward(self, input):\n",
        "        pos = input[:,:3]\n",
        "        obs = input[:,3:]\n",
        "        obs = self.encoder(obs)\n",
        "        obs = obs.view(-1,  self.num_flat_features(obs))\n",
        "\n",
        "        output = torch.cat([pos, obs],axis=1)\n",
        "        output = F.relu(self.fc1(output))\n",
        "        output = F.relu(self.fc2(output))    \n",
        "        output = F.relu(self.fc3(output))                        \n",
        "        output = F.relu(self.fc4(output))\n",
        "        return output\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "model = CNN_2dim()\n",
        "oss_fn = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "loss_calcularion_interval: int = 100 #how often you print running_loss\n",
        "batchsize = 100\n",
        "\n",
        "def saveModel():\n",
        "    path = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/learned_model.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def train(num_epochs):\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "\n",
        "    test_n = x_train.shape[0] # test_num\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i in range(0, test_n, batchsize):\n",
        "            x = x_train[i: i+batchsize]\n",
        "            y = y_train[i: i+batchsize]\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(x)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, y)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 1,000 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i/batchsize % loss_calcularion_interval == loss_calcularion_interval-1:    \n",
        "                # print every 1000 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.5f' %\n",
        "                      (epoch + 1, i + 1, running_loss/loss_calcularion_interval))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "    saveModel()\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "    # Let's build our model\n",
        "    train(20)"
      ],
      "metadata": {
        "id": "9RnSu6U64DEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_calcularion_interval: int = 5\n",
        "def eval():\n",
        "    test_n = x_test.shape[0] # test_num\n",
        "    running_loss = 0.0\n",
        "    for i in range(0, test_n, batchsize):\n",
        "        x = x_test[i: i+batchsize]\n",
        "        y = y_test[i: i+batchsize]\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # predict classes using images from the training set\n",
        "        outputs = model(x)\n",
        "        # compute the loss based on model output and real labels\n",
        "        loss = loss_fn(outputs, y)\n",
        "        # backpropagate the loss\n",
        "        # loss.backward()\n",
        "        # # adjust parameters based on the calculated gradients\n",
        "        # optimizer.step()\n",
        "\n",
        "        # Let's print statistics for every 1,000 images\n",
        "        running_loss += loss.item()     # extract the loss value\n",
        "        if i/batchsize % loss_calcularion_interval == loss_calcularion_interval-1:    \n",
        "            # print every 1000 (twice per epoch) \n",
        "            print('[%5d] loss: %.5f' %\n",
        "                    (i + 1, running_loss/loss_calcularion_interval))\n",
        "            # zero the loss\n",
        "            running_loss = 0.0\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "    # Let's build our model\n",
        "    eval()"
      ],
      "metadata": {
        "id": "hxq3IZF89cGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#学習結果検証"
      ],
      "metadata": {
        "id": "VbLa_1vxWNZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadModel():\n",
        "    path = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/learned_model.pth\"\n",
        "    model = CNN_2dim()\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    # modelのparameterの変更をなくすため\n",
        "    # https://tips-memo.com/pytorch-parameters-stop\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7RSB27_j-ITD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # hyper parameters\n",
        "    robot_theta = [0,60,0]\n",
        "    edge_l = 0.6\n",
        "    fly_area=[[0,-5.0],[60,5.0]]\n",
        "    tree_csv=\"/content/drive/MyDrive/先端人工知能論_プロジェクト/tree_folder\"\n",
        "    x_add_range=2.0\n",
        "    y_add_range=2.0\n",
        "    thetas = [5,15,25,35,45,60,75,90,105,120,135,150,165]\n",
        "    thetas = [np.deg2rad(theta) for theta in thetas]\n",
        "    act_norm = 0.4\n",
        "    state_data = np.empty((0,3+len(thetas)*2), float)\n",
        "    act_data = np.empty((0,3),float)\n",
        "\n",
        "    CONNECTION_RETRY = 8\n",
        "\n",
        "    file_num = 500\n",
        "    # environment making\n",
        "    init_pos=[5.0,-1,0]\n",
        "    goal_pos=[10.0,0,0]\n",
        "    node_num=100\n",
        "    sample_data=True\n",
        "    for i in range(1, CONNECTION_RETRY + 1):\n",
        "        try:\n",
        "            prm = Prm(robot_theta = robot_theta, edge_l=edge_l, fly_area=fly_area ,tree_csv=tree_csv, file_num=file_num, x_add_range=x_add_range, y_add_range=y_add_range, act_norm = act_norm)\n",
        "            prm.prm_planning(init_pos=init_pos, goal_pos=goal_pos, node_num=node_num)\n",
        "        except InitCollisionError as e:\n",
        "            print(\"In\", file_num, \" start or goal is collide. retry:{i}/{max}\".format(i=i,max=CONNECTION_RETRY))\n",
        "            print(\"error type is \",str(type(e)))\n",
        "            init_pos = [pos + random.uniform(-0.3, 0.3) for pos in init_pos]\n",
        "            goal_pos = [pos + random.uniform(-0.3, 0.3) for pos in goal_pos]\n",
        "            if i==CONNECTION_RETRY:\n",
        "                sample_data=False\n",
        "        except GoalCollisionError as e:\n",
        "            print(\"In\", file_num, \" start or goal is collide. retry:{i}/{max}\".format(i=i,max=CONNECTION_RETRY))\n",
        "            print(\"error type is \",str(type(e)))\n",
        "            init_pos = [pos + random.uniform(-0.3, 0.3) for pos in init_pos]\n",
        "            goal_pos = [pos + random.uniform(-0.3, 0.3) for pos in goal_pos]\n",
        "            if i==CONNECTION_RETRY:\n",
        "                sample_data=False\n",
        "        else:\n",
        "            break\n",
        "    env = Env(robot_theta = robot_theta, edge_l=edge_l, fly_area=fly_area, tree_csv=tree_csv, file_num=file_num, init_pos=init_pos, goal_pos=goal_pos, thetas=thetas)\n",
        "    model = loadModel()\n",
        "\n",
        "    # running environment and collecting data\n",
        "    pos = init_pos\n",
        "    act = prm.forward(pos)\n",
        "    # print(\"prm.current_edge is :\",prm.current_edge)\n",
        "    new_obs = env.step(act)\n",
        "    print(\"type(new_obs): \",type(new_obs))\n",
        "\n",
        "    for _ in range(30):\n",
        "        # state_data = np.hstack([state_data, new_obs])\n",
        "        state_data = np.append(state_data, new_obs.reshape(1,-1), axis=0)\n",
        "        new_obs = new_obs.reshape(1,-1)\n",
        "        # numpy to pytorch tensor for model calculation (cf. https://tzmi.hatenablog.com/entry/2020/02/16/170928)\n",
        "        new_obs = torch.from_numpy(new_obs.astype(np.float32)).clone()\n",
        "        act = model(new_obs)\n",
        "        act_data = np.append(act_data, act.reshape(1,-1), axis=0)\n",
        "        new_obs = env.step(act.flatten())\n",
        "        pos = env.pos\n",
        "    state_data = state_data[1:]\n",
        "    act_data = act_data[1:]"
      ],
      "metadata": {
        "id": "RG6mNqho_DVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(state_data[:,0])"
      ],
      "metadata": {
        "id": "iU32_0AjFI62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.collections as mc\n",
        "from google.colab import files\n",
        "figure, axes = plt.subplots()\n",
        "tree_csv = \"/content/drive/MyDrive/先端人工知能論_プロジェクト/tree_folder\"\n",
        "file_num = 500\n",
        "fig_num:int = 0\n",
        "def visualize(given_pos: list):\n",
        "    path = tree_csv+\"/environment_\" + str(file_num) + \"/static_obstacles.csv\"\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            x = float(row[1])\n",
        "            y = float(row[2])\n",
        "            r = float(row[8]) #+body_size\n",
        "            draw_circle = plt.Circle((x, y), r)\n",
        "            axes.add_artist(draw_circle)\n",
        "\n",
        "    CoG_pos = np.array([\n",
        "    [given_pos[0]],\n",
        "    [given_pos[1]]\n",
        "    ])\n",
        "    yaw = given_pos[2]\n",
        "    r = np.array([\n",
        "    [np.cos(yaw), -np.sin(yaw)],\n",
        "    [np.sin(yaw), np.cos(yaw)]\n",
        "        ])\n",
        "    # print(\"prm.C_list: \",prm.C_list)\n",
        "    edge_list = [CoG_pos + r @ pos for pos in prm.C_list]\n",
        "    # print(\"edge_list: \",edge_list)\n",
        "    lines = [[(edge_list[i][0,0],edge_list[i][1,0]),(edge_list[i+1][0,0],edge_list[i+1][1,0])]\n",
        "    for i in range(len(edge_list)-1)]\n",
        "    lc = mc.LineCollection(lines, colors = \"g\",linewidths=2)\n",
        "    axes.add_collection(lc)\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,8))\n",
        "plt.xlim([0, 35])\n",
        "plt.ylim([-5.0, 5.0])\n",
        "\n",
        "x_list = state_data[:,0]\n",
        "y_list = state_data[:,1]\n",
        "yaw_list = state_data[:,2]\n",
        "\n",
        "for x,y,yaw in zip(x_list,y_list,yaw_list):\n",
        "    visualize([x,y,yaw])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nkltd98eAFPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_list"
      ],
      "metadata": {
        "id": "nmPTL8XqHR7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JSBq2-4CWQy6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZCFW44oqajh9oGqdcesZlJ1bC5gFd4l4",
      "authorship_tag": "ABX9TyPSvSeuUqXBHtpg5cX1rE3Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}